use crate::nodes;
use std::str::FromStr;

grammar;

pub Program: String = {
  Expr* => <>.join("\n\n")
}

Expr: String = {
  Stream,
  StructDeclaration,
  EnumDeclaration
}

// nonsense struct used to handle terminal ambiguity
FreeText: String = {
  <text: r"[0-9A-Za-z/_\-]+"> => text.to_string(),
  <quoted_text: r#""[0-9A-Za-z/._\-\w]+""#> => quoted_text.to_string()
}

StructDeclaration: String = {
  "struct" <struct_name: FreeText> "{" <field_declarations: (StructFieldDeclaration ",")*> "}" => crate::nodes::StructDeclarationNode {
    name: struct_name,
    fields: {
      let mut v = Vec::new();
      for ((field_name, field_value_str), _comma_str) in field_declarations.into_iter() {
        let field_value = crate::nodes::Type::from_str(field_value_str.as_str())
          .expect("could not parse type in struct definition");
        v.push((field_name, field_value));
      }
      v
    }
  }.code()
}

StructFieldDeclaration: (String, String) = {
 <field_name: FreeText> ":" <field_value: FreeText> => {
  (field_name, field_value)
 }
}

EnumDeclaration: String = {
  "enum" <enum_name: FreeText> "{" <field_declarations: (EnumFieldDeclaration ",")*> "}" => crate::nodes::EnumDeclarationNode {
    name: enum_name,
    fields: field_declarations
      .into_iter()
      .map(
        |((field_name, field_value_str), _comma_str)|
          (field_name, field_value_str)
      )
      .collect::<Vec<(String, Option<String>)>>()
  }.code()
}

EnumFieldDeclaration: (String, Option<String>) = {
 <field_name: FreeText> "=" <field_value: FreeText> => {
  (field_name, Some(field_value))
 },
 <field_name: FreeText> => {
  (field_name, None)
 }
}

Stream: String = {
  <inp: InputFunction> <funs:("." <StreamFunction>)*> "." <out: OutputFunction> => {
      let exp = nodes::StreamNode {
        inp,
        funs,
        out
      };
      exp.code()
    },
}

InputFunction: nodes::InputFunctionNode = {
  "range(" <n1: FreeText> "," <n2: FreeText> ")" => nodes::InputFunctionNode{
    variability: nodes::InputVariability::Constant,
    input_count: nodes::InputCount::Known((n2.parse::<num_bigint::BigInt>().expect("could not parse input as integer") - n1.parse::<num_bigint::BigInt>().expect("could not parse input as integer")).to_biguint().unwrap()),
    code: format!("::marigold::marigold_impl::futures::stream::iter({n1}..{n2})"),
  },
  "read_file(" <path: FreeText> "," "csv" ")" => nodes::InputFunctionNode {
    variability: nodes::InputVariability::Variable,
    input_count: nodes::InputCount::Unknown,
    code: {
      match path[1..path.len() - 1].rsplit('.').next() {
         Some(postfix) => match postfix {
           "gz" => format!("
           ::marigold::marigold_impl::csv_async::AsyncReader::from_reader(
             ::marigold::marigold_impl::async_compression::tokio::bufread::GzipDecoder::new(
              ::marigold::marigold_impl::tokio::io::BufReader::new(
                ::marigold::marigold_impl::tokio::fs::File::open({path})
                  .await
                  .expect(\"Marigold could not open file\")
              )
             ).compat()
           ).into_records()
           "),
           postfix => format!("
           ::marigold::marigold_impl::csv_async::AsyncReader::from_reader(
              ::marigold::marigold_impl::tokio::fs::File::open({path})
               .await
               .expect(\"Marigold could not open file\")
               .compat()
           ).into_records()
           ")
         },
         None => format!("
         ::marigold::marigold_impl::csv_async::AsyncReader::from_reader(
          ::marigold::marigold_impl::tokio::fs::File::open({path})
           .await
           .expect(\"Marigold could not open file\")
           .compat()
         ).into_records()
         ")
       }
     }}
     ,
  "read_file(" <path: FreeText> "," "csv" "," "infer_compression" "=" "false" ")" => nodes::InputFunctionNode {
    variability: nodes::InputVariability::Variable,
    input_count: nodes::InputCount::Unknown,
    code: format!("::marigold::marigold_impl::csv_async::AsyncReader::from_reader(
      ::marigold::marigold_impl::tokio::fs::File::open({path})
        .await
        .expect(\"Marigold could not open file\")
        .compat()
    ).into_records()")
  },
  "read_file(" <path: FreeText> "," "csv" "," "struct" "=" <deserialization_struct: FreeText> ")" => nodes::InputFunctionNode {
    variability: nodes::InputVariability::Variable,
    input_count: nodes::InputCount::Unknown,
    code: {
      match path[1..path.len() - 1].rsplit('.').next() {
         Some(postfix) => match postfix {
           "gz" => format!("
           ::marigold::marigold_impl::csv_async::AsyncDeserializer::from_reader(
             ::marigold::marigold_impl::async_compression::tokio::bufread::GzipDecoder::new(
              ::marigold::marigold_impl::tokio::io::BufReader::new(
                ::marigold::marigold_impl::tokio::fs::File::open({path})
                  .await
                  .expect(\"Marigold could not open file\")
              )
             ).compat()
           ).into_deserialize::<{deserialization_struct}>()
           "),
           postfix => format!("
           ::marigold::marigold_impl::csv_async::AsyncDeserializer::from_reader(
              ::marigold::marigold_impl::tokio::fs::File::open({path})
               .await
               .expect(\"Marigold could not open file\")
               .compat()
           ).into_deserialize::<{deserialization_struct}>()
           ")
         },
         None => format!("
         ::marigold::marigold_impl::csv_async::AsyncDeserializer::from_reader(
          ::marigold::marigold_impl::tokio::fs::File::open({path})
           .await
           .expect(\"Marigold could not open file\")
           .compat()
         ).into_deserialize::<{deserialization_struct}>()
         ")
       }
    }
  },
  "read_file(" <path: FreeText> "," "csv" "," "struct" "=" <deserialization_struct: FreeText> "," "infer_compression" "=" "false" ")" => nodes::InputFunctionNode {
    variability: nodes::InputVariability::Variable,
    input_count: nodes::InputCount::Unknown,
    code: format!("
      ::marigold::marigold_impl::csv_async::AsyncDeserializer::from_reader(
         ::marigold::marigold_impl::tokio::fs::File::open({path})
          .await
          .expect(\"Marigold could not open file\")
          .compat()
      ).into_deserialize::<{deserialization_struct}>()
    ")
  }
}

StreamFunction: nodes::StreamFunctionNode = {
  "permutations("<n: FreeText> ")" => nodes::StreamFunctionNode {
    code: format!("permutations({n}).await")
  },
  "permutations_with_replacement("<n: FreeText> ")" => nodes::StreamFunctionNode {
    code: format!("collect_and_apply(|values| async {{
              ::marigold::marigold_impl::gen_nested_iter_yield::nested_iter_yield!(values.iter(), {n}, .to_owned(), ::marigold::marigold_impl::)
          }})
          .await
          .await
    ")
  },
  "combinations("<n: FreeText> ")" =>  nodes::StreamFunctionNode {
    code: format!("combinations({n}).await")
  },
  "keep_first_n(" <n: FreeText> "," <value_fn: FreeText> ")" =>  nodes::StreamFunctionNode {
    code: format!("keep_first_n({n}, {value_fn}).await")
  },
  "filter(" <filter_fn: FreeText> ")" => nodes::StreamFunctionNode {
    code: format!("filter(|v| futures::future::ready({filter_fn}(v)))")
    // filters have a bad type that doesn't allow them to compile if passed
    // an actual async function, so wrap a sync function in a fake future until
    // the filter types are updated.
  },
  "filter_map(" <filter_map_fn: FreeText> ")" => nodes::StreamFunctionNode {
    code: format!("filter_map({filter_map_fn})")
  },
  "to_vec()" =>  nodes::StreamFunctionNode {
    code: format!("collect::<std::vec::Vec<_>>().await")
  },
  "map(" <mapping_fn: FreeText> ")" => nodes::StreamFunctionNode {
    code: format!("map({mapping_fn})")
  },
  "ok()" => nodes::StreamFunctionNode {
    code: format!("filter(|r| futures::future::ready(r.is_ok()))
      .map(|r| r.unwrap())")
  },
  "ok_or_panic()" => nodes::StreamFunctionNode {
    code: "map(|r| r.unwrap())".to_string()
  }
}

OutputFunction: nodes::OutputFunctionNode = {
  "return" => nodes::OutputFunctionNode {
    stream_prefix: "return".to_string(),
    stream_postfix: ";".to_string(),
  },
  "write_file(" <path: FreeText> "," "csv" ")" => nodes::OutputFunctionNode {
    stream_prefix: format!("{{

      if let Some(parent) = ::std::path::Path::new({path}).parent() {{
        ::marigold::marigold_impl::tokio::fs::create_dir_all(parent)
          .await
          .expect(\"could not create parent directory for output file\");
      }}

      let mut output_csv_writer = std::sync::Arc::new(
        ::marigold::marigold_impl::tokio::sync::Mutex::new(
          ::marigold::marigold_impl::csv_async::AsyncSerializer::from_writer(
            ::marigold::marigold_impl::tokio::fs::File::create({path})
               .await
               .expect(\"Could not write to file\")
               .compat()
          )
        )
      );

      let mut stream_to_write =

     "),
    stream_postfix: "
        ;
        {
          let cloned_writer = output_csv_writer.clone();
          stream_to_write.for_each(
            |v| async {
              cloned_writer
                .clone()
                .lock()
                .await
                .serialize(v)
                .await
                .expect(\"could not write record to CSV\");
            }
          ).await;
        }
    }".to_string(),
  },
  "write_file(" <path: FreeText> "," "csv" "," "compression" "=" "gz" ")" => nodes::OutputFunctionNode {
    stream_prefix: format!("{{

      if let Some(parent) = std::path::Path::new({path}).parent() {{
        ::marigold::marigold_impl::tokio::fs::create_dir_all(parent)
          .await
          .expect(\"could not create parent directory for output file\");
      }}

      let mut output_csv_writer = std::sync::Arc::new(
        ::marigold::marigold_impl::tokio::sync::Mutex::new(
          ::marigold::marigold_impl::flate2::write::GzEncoder(
            ::marigold::marigold_impl::csv_async::AsyncSerializer::from_writer(
              ::marigold::marigold_impl::tokio::fs::File::create({path})
                 .await
                 .expect(\"Could not write to file\")
                 .compat()
            ),
            ::marigold::marigold_impl::flate2::Compression::best()
          )
        )
      );

      let mut stream_to_write =

     "),
    stream_postfix: "
        ;
        {
          let cloned_writer = output_csv_writer.clone();
          stream_to_write.for_each(
            |v| async {
              cloned_writer
                .clone()
                .lock()
                .await
                .serialize(v)
                .await
                .expect(\"could not write record to CSV\");
            }
          ).await;
        }
    }".to_string(),
  }
}
