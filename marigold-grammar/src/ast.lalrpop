use crate::nodes;
use std::str::FromStr;

grammar;

pub Program: String = {
  Expr* => {
    let mut expressions = std::collections::HashMap::new();
    <>
      .into_iter()
      .for_each(
        |expression|
          expressions
            .entry(expression.placement)
            .or_insert(Vec::new())
            .push(expression.code)
      );
    let mut output = "async {
    use ::marigold::marigold_impl::*;
    ".to_string();

    let before_streams = expressions
      .entry(nodes::Placement::BeforeStreams)
      .or_insert(Vec::new())
      .join("\n\n");

    output.push_str(&before_streams);
    output.push_str("

    ::marigold::marigold_impl::futures::stream::select_all(vec![
    ");

    let returning_stream_vec = expressions
      .entry(nodes::Placement::ReturningStream)
      .or_insert(Vec::new());

    let n_returning_streams = returning_stream_vec.len();

    output.push_str(returning_stream_vec.join(",\n\n").as_str());

    if returning_stream_vec.len() > 0 {
      output.push_str(",\n");
    }

    output.push_str(expressions
      .entry(nodes::Placement::StreamWithoutSpecificPlacement)
      .or_insert(Vec::new())
      .join(",\n\n").as_str());

    output.push_str("])");

    if n_returning_streams == 0 {
      output.push_str(".collect::<Vec<()>>()");
      // ^ completes the stream; vec will always have a length of 0.
    }
    output.push_str("\n}");

    output
  }
}

Expr: nodes::ExpressionWithPlacement = {
  Stream,
  StructDeclaration,
  EnumDeclaration
}

// nonsense struct used to handle terminal ambiguity
FreeText: String = {
  <text: r"[0-9A-Za-z/_\-]+"> => text.to_string()
}

// nonsense struct used to handle terminal ambiguity
QuotedFreeText: String = {
  <quoted_text: r#""[0-9A-Za-z/._\-\w]+""#> => quoted_text.to_string(),
  <variable_name: r"[0-9A-Za-z/_\-]+"> => variable_name.to_string()
}

StructDeclaration: nodes::ExpressionWithPlacement = {
  "struct" <struct_name: FreeText> "{" <field_declarations: (StructFieldDeclaration ",")*> "}" => nodes::ExpressionWithPlacement {
    placement: nodes::Placement::BeforeStreams,
    code: crate::nodes::StructDeclarationNode {
      name: struct_name,
      fields: {
        let mut v = Vec::new();
        for ((field_name, field_value_str), _comma_str) in field_declarations.into_iter() {
          let field_value = crate::nodes::Type::from_str(field_value_str.as_str())
            .expect("could not parse type in struct definition");
          v.push((field_name, field_value));
        }
        v
      }
    }.code(),
  }
}

StructFieldDeclaration: (String, String) = {
 <field_name: FreeText> ":" <field_value: FreeText> => {
  (field_name, field_value)
 }
}

EnumDeclaration: nodes::ExpressionWithPlacement = {
  "enum" <enum_name: FreeText> "{" <field_declarations: (EnumFieldDeclaration ",")*> "}" => nodes::ExpressionWithPlacement {
    placement: nodes::Placement::BeforeStreams,
    code: crate::nodes::EnumDeclarationNode {
      name: enum_name,
      fields: field_declarations
        .into_iter()
        .map(
          |((field_name, field_value_str), _comma_str)|
            (field_name, field_value_str)
        )
        .collect::<Vec<(String, Option<String>)>>()
    }.code(),
  }
}

EnumFieldDeclaration: (String, Option<String>) = {
 <field_name: FreeText> "=" <field_value: QuotedFreeText> => {
  (field_name, Some(field_value))
 },
 <field_name: FreeText> => {
  (field_name, None)
 }
}

Stream: nodes::ExpressionWithPlacement = {
  <inp: InputFunction> <funs:("." <StreamFunction>)*> "." <out: OutputFunction> => {
      let placement = out.placement;
      let exp = nodes::StreamNode {
        inp,
        funs,
        out
      };
      nodes::ExpressionWithPlacement {
        placement: placement,
        code: exp.code(),
      }
    },
}

InputFunction: nodes::InputFunctionNode = {
  "range(" <n1: FreeText> "," <n2: FreeText> ")" => nodes::InputFunctionNode{
    variability: nodes::InputVariability::Constant,
    input_count: nodes::InputCount::Known((n2.parse::<num_bigint::BigInt>().expect("could not parse input as integer") - n1.parse::<num_bigint::BigInt>().expect("could not parse input as integer")).to_biguint().unwrap()),
    code: format!("::marigold::marigold_impl::futures::stream::iter({n1}..{n2})"),
  },
  "read_file(" <path: QuotedFreeText> "," "csv" "," "struct" "=" <deserialization_struct: FreeText> ")" => nodes::InputFunctionNode {
    variability: nodes::InputVariability::Variable,
    input_count: nodes::InputCount::Unknown,
    code: {
      match path[1..path.len() - 1].rsplit('.').next() {
         Some(postfix) => match postfix {
           "gz" => format!("
           ::marigold::marigold_impl::csv_async::AsyncDeserializer::from_reader(
             ::marigold::marigold_impl::async_compression::tokio::bufread::GzipDecoder::new(
              ::marigold::marigold_impl::tokio::io::BufReader::new(
                ::marigold::marigold_impl::tokio::fs::File::open({path})
                  .await
                  .expect(\"Marigold could not open file\")
              )
             ).compat()
           ).into_deserialize::<{deserialization_struct}>()
           "),
           postfix => format!("
           ::marigold::marigold_impl::csv_async::AsyncDeserializer::from_reader(
              ::marigold::marigold_impl::tokio::fs::File::open({path})
               .await
               .expect(\"Marigold could not open file\")
               .compat()
           ).into_deserialize::<{deserialization_struct}>()
           ")
         },
         None => format!("
         ::marigold::marigold_impl::csv_async::AsyncDeserializer::from_reader(
          ::marigold::marigold_impl::tokio::fs::File::open({path})
           .await
           .expect(\"Marigold could not open file\")
           .compat()
         ).into_deserialize::<{deserialization_struct}>()
         ")
       }
    }
  },
  "read_file(" <path: QuotedFreeText> "," "csv" "," "struct" "=" <deserialization_struct: FreeText> "," "infer_compression" "=" "false" ")" => nodes::InputFunctionNode {
    variability: nodes::InputVariability::Variable,
    input_count: nodes::InputCount::Unknown,
    code: format!("
      ::marigold::marigold_impl::csv_async::AsyncDeserializer::from_reader(
         ::marigold::marigold_impl::tokio::fs::File::open({path})
          .await
          .expect(\"Marigold could not open file\")
          .compat()
      ).into_deserialize::<{deserialization_struct}>()
    ")
  }
}

StreamFunction: nodes::StreamFunctionNode = {
  "permutations("<n: FreeText> ")" => nodes::StreamFunctionNode {
    code: format!("permutations({n}).await")
  },
  "permutations_with_replacement("<n: FreeText> ")" => nodes::StreamFunctionNode {
    code: format!("collect_and_apply(|values| async {{
                ::marigold::marigold_impl::gen_nested_iter_yield::nested_iter_yield!(values.iter(), {n}, .to_owned(), ::marigold::marigold_impl::)
          }})
          .await
          .await
    ")
  },
  "combinations("<n: FreeText> ")" =>  nodes::StreamFunctionNode {
    code: format!("combinations({n}).await")
  },
  "keep_first_n(" <n: FreeText> "," <value_fn: FreeText> ")" =>  nodes::StreamFunctionNode {
    code: format!("keep_first_n({n}, {value_fn}).await")
  },
  "filter(" <filter_fn: FreeText> ")" => nodes::StreamFunctionNode {
    code: format!("filter(|v| futures::future::ready({filter_fn}(v)))")
    // filters have a bad type that doesn't allow them to compile if passed
    // an actual async function, so wrap a sync function in a fake future until
    // the filter types are updated.
  },
  "filter_map(" <filter_map_fn: FreeText> ")" => nodes::StreamFunctionNode {
    code: format!("filter_map({filter_map_fn})")
  },
  "map(" <mapping_fn: FreeText> ")" => nodes::StreamFunctionNode {
    code: format!("map({mapping_fn})")
  },
  "ok()" => nodes::StreamFunctionNode {
    code: format!("filter(|r| futures::future::ready(r.is_ok()))
      .map(|r| r.unwrap())")
  },
  "ok_or_panic()" => nodes::StreamFunctionNode {
    code: "map(|r| r.unwrap())".to_string()
  }
}

OutputFunction: nodes::OutputFunctionNode = {
  "return" => nodes::OutputFunctionNode {
    stream_prefix: "".to_string(),
    stream_postfix: "".to_string(),
    placement: nodes::Placement::ReturningStream,
  },
  "write_file(" <path: QuotedFreeText> "," "csv" ")" => nodes::OutputFunctionNode {
    stream_prefix: format!("{{

      if let Some(parent) = ::std::path::Path::new({path}).parent() {{
        ::marigold::marigold_impl::tokio::fs::create_dir_all(parent)
          .await
          .expect(\"could not create parent directory for output file\");
      }}

      let mut output_csv_writer = std::sync::Arc::new(
        ::marigold::marigold_impl::tokio::sync::Mutex::new(
          ::marigold::marigold_impl::csv_async::AsyncSerializer::from_writer(
            ::marigold::marigold_impl::tokio::fs::File::create({path})
               .await
               .expect(\"Could not write to file\")
               .compat()
          )
        )
      );

      let mut stream_to_write =

     "),
    stream_postfix: "
        ;
        {
          let cloned_writer = output_csv_writer.clone();
          stream_to_write.filter_map(
            |v| async {
              cloned_writer
                .clone()
                .lock()
                .await
                .serialize(v)
                .await
                .expect(\"could not write record to CSV\");
              None
            }
          )
        }
    }".to_string(),
    placement: nodes::Placement::StreamWithoutSpecificPlacement,
  },
  "write_file(" <path: QuotedFreeText> "," "csv" "," "compression" "=" "gz" ")" => nodes::OutputFunctionNode {
    stream_prefix: format!("{{

      if let Some(parent) = std::path::Path::new({path}).parent() {{
        ::marigold::marigold_impl::tokio::fs::create_dir_all(parent)
          .await
          .expect(\"could not create parent directory for output file\");
      }}

      let mut output_csv_writer = std::sync::Arc::new(
        ::marigold::marigold_impl::tokio::sync::Mutex::new(
          ::marigold::marigold_impl::flate2::write::GzEncoder(
            ::marigold::marigold_impl::csv_async::AsyncSerializer::from_writer(
              ::marigold::marigold_impl::tokio::fs::File::create({path})
                 .await
                 .expect(\"Could not write to file\")
                 .compat()
            ),
            ::marigold::marigold_impl::flate2::Compression::best()
          )
        )
      );

      let mut stream_to_write =

     "),
    stream_postfix: "
        ;
        {
          let cloned_writer = output_csv_writer.clone();
          stream_to_write.filter_map(
            |v| async {
              cloned_writer
                .clone()
                .lock()
                .await
                .serialize(v)
                .await
                .expect(\"could not write record to CSV\");
                None
            }
          )
        }
    }".to_string(),
    placement: nodes::Placement::StreamWithoutSpecificPlacement,
  }
}
